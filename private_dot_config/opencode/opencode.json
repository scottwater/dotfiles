{
  "$schema": "https://opencode.ai/config.json",
  "command": {
    "test-browser": {
      "description": "Run browser tests on pages affected by current PR or branch",
      "template": "# Browser Test Command\n\n<command_purpose>Run end-to-end browser tests on pages affected by a PR or branch changes using agent-browser CLI.</command_purpose>\n\n## CRITICAL: Use agent-browser CLI Only\n\n**DO NOT use Chrome MCP tools (mcp__claude-in-chrome__*).**\n\nThis command uses the `agent-browser` CLI exclusively. The agent-browser CLI is a Bash-based tool from Vercel that runs headless Chromium. It is NOT the same as Chrome browser automation via MCP.\n\nIf you find yourself calling `mcp__claude-in-chrome__*` tools, STOP. Use `agent-browser` Bash commands instead.\n\n## Introduction\n\n<role>QA Engineer specializing in browser-based end-to-end testing</role>\n\nThis command tests affected pages in a real browser, catching issues that unit tests miss:\n- JavaScript integration bugs\n- CSS/layout regressions\n- User workflow breakages\n- Console errors\n\n## Prerequisites\n\n<requirements>\n- Local development server running (e.g., `bin/dev`, `rails server`, `npm run dev`)\n- agent-browser CLI installed (see Setup below)\n- Git repository with changes to test\n</requirements>\n\n## Setup\n\n**Check installation:**\n```bash\ncommand -v agent-browser >/dev/null 2>&1 && echo \"Installed\" || echo \"NOT INSTALLED\"\n```\n\n**Install if needed:**\n```bash\nnpm install -g agent-browser\nagent-browser install  # Downloads Chromium (~160MB)\n```\n\nSee the `agent-browser` skill for detailed usage.\n\n## Main Tasks\n\n### 0. Verify agent-browser Installation\n\nBefore starting ANY browser testing, verify agent-browser is installed:\n\n```bash\ncommand -v agent-browser >/dev/null 2>&1 && echo \"Ready\" || (echo \"Installing...\" && npm install -g agent-browser && agent-browser install)\n```\n\nIf installation fails, inform the user and stop.\n\n### 1. Ask Browser Mode\n\n<ask_browser_mode>\n\nBefore starting tests, ask user if they want to watch the browser:\n\nUse AskUserQuestion with:\n- Question: \"Do you want to watch the browser tests run?\"\n- Options:\n  1. **Headed (watch)** - Opens visible browser window so you can see tests run\n  2. **Headless (faster)** - Runs in background, faster but invisible\n\nStore the choice and use `--headed` flag when user selects \"Headed\".\n\n</ask_browser_mode>\n\n### 2. Determine Test Scope\n\n<test_target> $ARGUMENTS </test_target>\n\n<determine_scope>\n\n**If PR number provided:**\n```bash\ngh pr view [number] --json files -q '.files[].path'\n```\n\n**If 'current' or empty:**\n```bash\ngit diff --name-only main...HEAD\n```\n\n**If branch name provided:**\n```bash\ngit diff --name-only main...[branch]\n```\n\n</determine_scope>\n\n### 3. Map Files to Routes\n\n<file_to_route_mapping>\n\nMap changed files to testable routes:\n\n| File Pattern | Route(s) |\n|-------------|----------|\n| `app/views/users/*` | `/users`, `/users/:id`, `/users/new` |\n| `app/controllers/settings_controller.rb` | `/settings` |\n| `app/javascript/controllers/*_controller.js` | Pages using that Stimulus controller |\n| `app/components/*_component.rb` | Pages rendering that component |\n| `app/views/layouts/*` | All pages (test homepage at minimum) |\n| `app/assets/stylesheets/*` | Visual regression on key pages |\n| `app/helpers/*_helper.rb` | Pages using that helper |\n| `src/app/*` (Next.js) | Corresponding routes |\n| `src/components/*` | Pages using those components |\n\nBuild a list of URLs to test based on the mapping.\n\n</file_to_route_mapping>\n\n### 4. Verify Server is Running\n\n<check_server>\n\nBefore testing, verify the local server is accessible:\n\n```bash\nagent-browser open http://localhost:3000\nagent-browser snapshot -i\n```\n\nIf server is not running, inform user:\n```markdown\n**Server not running**\n\nPlease start your development server:\n- Rails: `bin/dev` or `rails server`\n- Node/Next.js: `npm run dev`\n\nThen run `/test-browser` again.\n```\n\n</check_server>\n\n### 5. Test Each Affected Page\n\n<test_pages>\n\nFor each affected route, use agent-browser CLI commands (NOT Chrome MCP):\n\n**Step 1: Navigate and capture snapshot**\n```bash\nagent-browser open \"http://localhost:3000/[route]\"\nagent-browser snapshot -i\n```\n\n**Step 2: For headed mode (visual debugging)**\n```bash\nagent-browser --headed open \"http://localhost:3000/[route]\"\nagent-browser --headed snapshot -i\n```\n\n**Step 3: Verify key elements**\n- Use `agent-browser snapshot -i` to get interactive elements with refs\n- Page title/heading present\n- Primary content rendered\n- No error messages visible\n- Forms have expected fields\n\n**Step 4: Test critical interactions**\n```bash\nagent-browser click @e1  # Use ref from snapshot\nagent-browser snapshot -i\n```\n\n**Step 5: Take screenshots**\n```bash\nagent-browser screenshot page-name.png\nagent-browser screenshot --full page-name-full.png  # Full page\n```\n\n</test_pages>\n\n### 6. Human Verification (When Required)\n\n<human_verification>\n\nPause for human input when testing touches:\n\n| Flow Type | What to Ask |\n|-----------|-------------|\n| OAuth | \"Please sign in with [provider] and confirm it works\" |\n| Email | \"Check your inbox for the test email and confirm receipt\" |\n| Payments | \"Complete a test purchase in sandbox mode\" |\n| SMS | \"Verify you received the SMS code\" |\n| External APIs | \"Confirm the [service] integration is working\" |\n\nUse AskUserQuestion:\n```markdown\n**Human Verification Needed**\n\nThis test touches the [flow type]. Please:\n1. [Action to take]\n2. [What to verify]\n\nDid it work correctly?\n1. Yes - continue testing\n2. No - describe the issue\n```\n\n</human_verification>\n\n### 7. Handle Failures\n\n<failure_handling>\n\nWhen a test fails:\n\n1. **Document the failure:**\n   - Screenshot the error state: `agent-browser screenshot error.png`\n   - Note the exact reproduction steps\n\n2. **Ask user how to proceed:**\n   ```markdown\n   **Test Failed: [route]**\n\n   Issue: [description]\n   Console errors: [if any]\n\n   How to proceed?\n   1. Fix now - I'll help debug and fix\n   2. Create todo - Add to todos/ for later\n   3. Skip - Continue testing other pages\n   ```\n\n3. **If \"Fix now\":**\n   - Investigate the issue\n   - Propose a fix\n   - Apply fix\n   - Re-run the failing test\n\n4. **If \"Create todo\":**\n   - Create `{id}-pending-p1-browser-test-{description}.md`\n   - Continue testing\n\n5. **If \"Skip\":**\n   - Log as skipped\n   - Continue testing\n\n</failure_handling>\n\n### 8. Test Summary\n\n<test_summary>\n\nAfter all tests complete, present summary:\n\n```markdown\n## Browser Test Results\n\n**Test Scope:** PR #[number] / [branch name]\n**Server:** http://localhost:3000\n\n### Pages Tested: [count]\n\n| Route | Status | Notes |\n|-------|--------|-------|\n| `/users` | Pass | |\n| `/settings` | Pass | |\n| `/dashboard` | Fail | Console error: [msg] |\n| `/checkout` | Skip | Requires payment credentials |\n\n### Console Errors: [count]\n- [List any errors found]\n\n### Human Verifications: [count]\n- OAuth flow: Confirmed\n- Email delivery: Confirmed\n\n### Failures: [count]\n- `/dashboard` - [issue description]\n\n### Created Todos: [count]\n- `005-pending-p1-browser-test-dashboard-error.md`\n\n### Result: [PASS / FAIL / PARTIAL]\n```\n\n</test_summary>\n\n## Quick Usage Examples\n\n```bash\n# Test current branch changes\n/test-browser\n\n# Test specific PR\n/test-browser 847\n\n# Test specific branch\n/test-browser feature/new-dashboard\n```\n\n## agent-browser CLI Reference\n\n**ALWAYS use these Bash commands. NEVER use mcp__claude-in-chrome__* tools.**\n\n```bash\n# Navigation\nagent-browser open <url>           # Navigate to URL\nagent-browser back                 # Go back\nagent-browser close                # Close browser\n\n# Snapshots (get element refs)\nagent-browser snapshot -i          # Interactive elements with refs (@e1, @e2, etc.)\nagent-browser snapshot -i --json   # JSON output\n\n# Interactions (use refs from snapshot)\nagent-browser click @e1            # Click element\nagent-browser fill @e1 \"text\"      # Fill input\nagent-browser type @e1 \"text\"      # Type without clearing\nagent-browser press Enter          # Press key\n\n# Screenshots\nagent-browser screenshot out.png       # Viewport screenshot\nagent-browser screenshot --full out.png # Full page screenshot\n\n# Headed mode (visible browser)\nagent-browser --headed open <url>      # Open with visible browser\nagent-browser --headed click @e1       # Click in visible browser\n\n# Wait\nagent-browser wait @e1             # Wait for element\nagent-browser wait 2000            # Wait milliseconds\n```"
    },
    "deepen-plan": {
      "description": "Enhance a plan with parallel research agents for each section to add depth, best practices, and implementation details",
      "template": "# Deepen Plan - Power Enhancement Mode\n\n## Introduction\n\n**Note: The current year is 2026.** Use this when searching for recent documentation and best practices.\n\nThis command takes an existing plan (from `/workflows:plan`) and enhances each section with parallel research agents. Each major element gets its own dedicated research sub-agent to find:\n- Best practices and industry patterns\n- Performance optimizations\n- UI/UX improvements (if applicable)\n- Quality enhancements and edge cases\n- Real-world implementation examples\n\nThe result is a deeply grounded, production-ready plan with concrete implementation details.\n\n## Plan File\n\n<plan_path> #$ARGUMENTS </plan_path>\n\n**If the plan path above is empty:**\n1. Check for recent plans: `ls -la docs/plans/`\n2. Ask the user: \"Which plan would you like to deepen? Please provide the path (e.g., `docs/plans/2026-01-15-feat-my-feature-plan.md`).\"\n\nDo not proceed until you have a valid plan file path.\n\n## Main Tasks\n\n### 1. Parse and Analyze Plan Structure\n\n<thinking>\nFirst, read and parse the plan to identify each major section that can be enhanced with research.\n</thinking>\n\n**Read the plan file and extract:**\n- [ ] Overview/Problem Statement\n- [ ] Proposed Solution sections\n- [ ] Technical Approach/Architecture\n- [ ] Implementation phases/steps\n- [ ] Code examples and file references\n- [ ] Acceptance criteria\n- [ ] Any UI/UX components mentioned\n- [ ] Technologies/frameworks mentioned (Rails, React, Python, TypeScript, etc.)\n- [ ] Domain areas (data models, APIs, UI, security, performance, etc.)\n\n**Create a section manifest:**\n```\nSection 1: [Title] - [Brief description of what to research]\nSection 2: [Title] - [Brief description of what to research]\n...\n```\n\n### 2. Discover and Apply Available Skills\n\n<thinking>\nDynamically discover all available skills and match them to plan sections. Don't assume what skills exist - discover them at runtime.\n</thinking>\n\n**Step 1: Discover ALL available skills from ALL sources**\n\n```bash\n# 1. Project-local skills (highest priority - project-specific)\nls .opencode/skills/\n\n# 2. User's global skills (~/.config/opencode/)\nls ~/.agents/skills/\n\n# 3. compound-engineering plugin skills\nls ~/.config/opencode/plugins/cache/*/compound-engineering/*/skills/\n\n# 4. ALL other installed plugins - check every plugin for skills\nfind ~/.config/opencode/plugins/cache -type d -name \"skills\" 2>/dev/null\n\n# 5. Also check installed_plugins.json for all plugin locations\ncat ~/.config/opencode/plugins/installed_plugins.json\n```\n\n**Important:** Check EVERY source. Don't assume compound-engineering is the only plugin. Use skills from ANY installed plugin that's relevant.\n\n**Step 2: For each discovered skill, read its SKILL.md to understand what it does**\n\n```bash\n# For each skill directory found, read its documentation\ncat [skill-path]/SKILL.md\n```\n\n**Step 3: Match skills to plan content**\n\nFor each skill discovered:\n- Read its SKILL.md description\n- Check if any plan sections match the skill's domain\n- If there's a match, spawn a sub-agent to apply that skill's knowledge\n\n**Step 4: Spawn a sub-agent for EVERY matched skill**\n\n**CRITICAL: For EACH skill that matches, spawn a separate sub-agent and instruct it to USE that skill.**\n\nFor each matched skill:\n```\nTask general-purpose: \"You have the [skill-name] skill available at [skill-path].\n\nYOUR JOB: Use this skill on the plan.\n\n1. Read the skill: cat [skill-path]/SKILL.md\n2. Follow the skill's instructions exactly\n3. Apply the skill to this content:\n\n[relevant plan section or full plan]\n\n4. Return the skill's full output\n\nThe skill tells you what to do - follow it. Execute the skill completely.\"\n```\n\n**Spawn ALL skill sub-agents in PARALLEL:**\n- 1 sub-agent per matched skill\n- Each sub-agent reads and uses its assigned skill\n- All run simultaneously\n- 10, 20, 30 skill sub-agents is fine\n\n**Each sub-agent:**\n1. Reads its skill's SKILL.md\n2. Follows the skill's workflow/instructions\n3. Applies the skill to the plan\n4. Returns whatever the skill produces (code, recommendations, patterns, reviews, etc.)\n\n**Example spawns:**\n```\nTask general-purpose: \"Use the dhh-rails-style skill at ~/.config/opencode/plugins/.../dhh-rails-style. Read SKILL.md and apply it to: [Rails sections of plan]\"\n\nTask general-purpose: \"Use the frontend-design skill at ~/.config/opencode/plugins/.../frontend-design. Read SKILL.md and apply it to: [UI sections of plan]\"\n\nTask general-purpose: \"Use the agent-native-architecture skill at ~/.config/opencode/plugins/.../agent-native-architecture. Read SKILL.md and apply it to: [agent/tool sections of plan]\"\n\nTask general-purpose: \"Use the security-patterns skill at ~/.agents/skills/security-patterns. Read SKILL.md and apply it to: [full plan]\"\n```\n\n**No limit on skill sub-agents. Spawn one for every skill that could possibly be relevant.**\n\n### 3. Discover and Apply Learnings/Solutions\n\n<thinking>\nCheck for documented learnings from /workflows:compound. These are solved problems stored as markdown files. Spawn a sub-agent for each learning to check if it's relevant.\n</thinking>\n\n**LEARNINGS LOCATION - Check these exact folders:**\n\n```\ndocs/solutions/           <-- PRIMARY: Project-level learnings (created by /workflows:compound)\n‚îú‚îÄ‚îÄ performance-issues/\n‚îÇ   ‚îî‚îÄ‚îÄ *.md\n‚îú‚îÄ‚îÄ debugging-patterns/\n‚îÇ   ‚îî‚îÄ‚îÄ *.md\n‚îú‚îÄ‚îÄ configuration-fixes/\n‚îÇ   ‚îî‚îÄ‚îÄ *.md\n‚îú‚îÄ‚îÄ integration-issues/\n‚îÇ   ‚îî‚îÄ‚îÄ *.md\n‚îú‚îÄ‚îÄ deployment-issues/\n‚îÇ   ‚îî‚îÄ‚îÄ *.md\n‚îî‚îÄ‚îÄ [other-categories]/\n    ‚îî‚îÄ‚îÄ *.md\n```\n\n**Step 1: Find ALL learning markdown files**\n\nRun these commands to get every learning file:\n\n```bash\n# PRIMARY LOCATION - Project learnings\nfind docs/solutions -name \"*.md\" -type f 2>/dev/null\n\n# If docs/solutions doesn't exist, check alternate locations:\nfind .opencode/docs -name \"*.md\" -type f 2>/dev/null\nfind ~/.config/opencode/docs -name \"*.md\" -type f 2>/dev/null\n```\n\n**Step 2: Read frontmatter of each learning to filter**\n\nEach learning file has YAML frontmatter with metadata. Read the first ~20 lines of each file to get:\n\n```yaml\n---\ntitle: \"N+1 Query Fix for Briefs\"\ncategory: performance-issues\ntags: [activerecord, n-plus-one, includes, eager-loading]\nmodule: Briefs\nsymptom: \"Slow page load, multiple queries in logs\"\nroot_cause: \"Missing includes on association\"\n---\n```\n\n**For each .md file, quickly scan its frontmatter:**\n\n```bash\n# Read first 20 lines of each learning (frontmatter + summary)\nhead -20 docs/solutions/**/*.md\n```\n\n**Step 3: Filter - only spawn sub-agents for LIKELY relevant learnings**\n\nCompare each learning's frontmatter against the plan:\n- `tags:` - Do any tags match technologies/patterns in the plan?\n- `category:` - Is this category relevant? (e.g., skip deployment-issues if plan is UI-only)\n- `module:` - Does the plan touch this module?\n- `symptom:` / `root_cause:` - Could this problem occur with the plan?\n\n**SKIP learnings that are clearly not applicable:**\n- Plan is frontend-only ‚Üí skip `database-migrations/` learnings\n- Plan is Python ‚Üí skip `rails-specific/` learnings\n- Plan has no auth ‚Üí skip `authentication-issues/` learnings\n\n**SPAWN sub-agents for learnings that MIGHT apply:**\n- Any tag overlap with plan technologies\n- Same category as plan domain\n- Similar patterns or concerns\n\n**Step 4: Spawn sub-agents for filtered learnings**\n\nFor each learning that passes the filter:\n\n```\nTask general-purpose: \"\nLEARNING FILE: [full path to .md file]\n\n1. Read this learning file completely\n2. This learning documents a previously solved problem\n\nCheck if this learning applies to this plan:\n\n---\n[full plan content]\n---\n\nIf relevant:\n- Explain specifically how it applies\n- Quote the key insight or solution\n- Suggest where/how to incorporate it\n\nIf NOT relevant after deeper analysis:\n- Say 'Not applicable: [reason]'\n\"\n```\n\n**Example filtering:**\n```\n# Found 15 learning files, plan is about \"Rails API caching\"\n\n# SPAWN (likely relevant):\ndocs/solutions/performance-issues/n-plus-one-queries.md      # tags: [activerecord] ‚úì\ndocs/solutions/performance-issues/redis-cache-stampede.md    # tags: [caching, redis] ‚úì\ndocs/solutions/configuration-fixes/redis-connection-pool.md  # tags: [redis] ‚úì\n\n# SKIP (clearly not applicable):\ndocs/solutions/deployment-issues/heroku-memory-quota.md      # not about caching\ndocs/solutions/frontend-issues/stimulus-race-condition.md    # plan is API, not frontend\ndocs/solutions/authentication-issues/jwt-expiry.md           # plan has no auth\n```\n\n**Spawn sub-agents in PARALLEL for all filtered learnings.**\n\n**These learnings are institutional knowledge - applying them prevents repeating past mistakes.**\n\n### 4. Launch Per-Section Research Agents\n\n<thinking>\nFor each major section in the plan, spawn dedicated sub-agents to research improvements. Use the Explore agent type for open-ended research.\n</thinking>\n\n**For each identified section, launch parallel research:**\n\n```\nTask Explore: \"Research best practices, patterns, and real-world examples for: [section topic].\nFind:\n- Industry standards and conventions\n- Performance considerations\n- Common pitfalls and how to avoid them\n- Documentation and tutorials\nReturn concrete, actionable recommendations.\"\n```\n\n**Also use Context7 MCP for framework documentation:**\n\nFor any technologies/frameworks mentioned in the plan, query Context7:\n```\nmcp__plugin_compound-engineering_context7__resolve-library-id: Find library ID for [framework]\nmcp__plugin_compound-engineering_context7__query-docs: Query documentation for specific patterns\n```\n\n**Use WebSearch for current best practices:**\n\nSearch for recent (2024-2026) articles, blog posts, and documentation on topics in the plan.\n\n### 5. Discover and Run ALL Review Agents\n\n<thinking>\nDynamically discover every available agent and run them ALL against the plan. Don't filter, don't skip, don't assume relevance. 40+ parallel agents is fine. Use everything available.\n</thinking>\n\n**Step 1: Discover ALL available agents from ALL sources**\n\n```bash\n# 1. Project-local agents (highest priority - project-specific)\nfind .opencode/agents -name \"*.md\" 2>/dev/null\n\n# 2. User's global agents (~/.config/opencode/)\nfind ~/.config/opencode/agents -name \"*.md\" 2>/dev/null\n\n# 3. compound-engineering plugin agents (all subdirectories)\nfind ~/.config/opencode/plugins/cache/*/compound-engineering/*/agents -name \"*.md\" 2>/dev/null\n\n# 4. ALL other installed plugins - check every plugin for agents\nfind ~/.config/opencode/plugins/cache -path \"*/agents/*.md\" 2>/dev/null\n\n# 5. Check installed_plugins.json to find all plugin locations\ncat ~/.config/opencode/plugins/installed_plugins.json\n\n# 6. For local plugins (isLocal: true), check their source directories\n# Parse installed_plugins.json and find local plugin paths\n```\n\n**Important:** Check EVERY source. Include agents from:\n- Project `.opencode/agents/`\n- User's `~/.config/opencode/agents/`\n- compound-engineering plugin (but SKIP workflow/ agents - only use review/, research/, design/, docs/)\n- ALL other installed plugins (agent-sdk-dev, frontend-design, etc.)\n- Any local plugins\n\n**For compound-engineering plugin specifically:**\n- USE: `agents/review/*` (all reviewers)\n- USE: `agents/research/*` (all researchers)\n- USE: `agents/design/*` (design agents)\n- USE: `agents/docs/*` (documentation agents)\n- SKIP: `agents/workflow/*` (these are workflow orchestrators, not reviewers)\n\n**Step 2: For each discovered agent, read its description**\n\nRead the first few lines of each agent file to understand what it reviews/analyzes.\n\n**Step 3: Launch ALL agents in parallel**\n\nFor EVERY agent discovered, launch a Task in parallel:\n\n```\nTask [agent-name]: \"Review this plan using your expertise. Apply all your checks and patterns. Plan content: [full plan content]\"\n```\n\n**CRITICAL RULES:**\n- Do NOT filter agents by \"relevance\" - run them ALL\n- Do NOT skip agents because they \"might not apply\" - let them decide\n- Launch ALL agents in a SINGLE message with multiple Task tool calls\n- 20, 30, 40 parallel agents is fine - use everything\n- Each agent may catch something others miss\n- The goal is MAXIMUM coverage, not efficiency\n\n**Step 4: Also discover and run research agents**\n\nResearch agents (like `best-practices-researcher`, `framework-docs-researcher`, `git-history-analyzer`, `repo-research-analyst`) should also be run for relevant plan sections.\n\n### 6. Wait for ALL Agents and Synthesize Everything\n\n<thinking>\nWait for ALL parallel agents to complete - skills, research agents, review agents, everything. Then synthesize all findings into a comprehensive enhancement.\n</thinking>\n\n**Collect outputs from ALL sources:**\n\n1. **Skill-based sub-agents** - Each skill's full output (code examples, patterns, recommendations)\n2. **Learnings/Solutions sub-agents** - Relevant documented learnings from /workflows:compound\n3. **Research agents** - Best practices, documentation, real-world examples\n4. **Review agents** - All feedback from every reviewer (architecture, security, performance, simplicity, etc.)\n5. **Context7 queries** - Framework documentation and patterns\n6. **Web searches** - Current best practices and articles\n\n**For each agent's findings, extract:**\n- [ ] Concrete recommendations (actionable items)\n- [ ] Code patterns and examples (copy-paste ready)\n- [ ] Anti-patterns to avoid (warnings)\n- [ ] Performance considerations (metrics, benchmarks)\n- [ ] Security considerations (vulnerabilities, mitigations)\n- [ ] Edge cases discovered (handling strategies)\n- [ ] Documentation links (references)\n- [ ] Skill-specific patterns (from matched skills)\n- [ ] Relevant learnings (past solutions that apply - prevent repeating mistakes)\n\n**Deduplicate and prioritize:**\n- Merge similar recommendations from multiple agents\n- Prioritize by impact (high-value improvements first)\n- Flag conflicting advice for human review\n- Group by plan section\n\n### 7. Enhance Plan Sections\n\n<thinking>\nMerge research findings back into the plan, adding depth without changing the original structure.\n</thinking>\n\n**Enhancement format for each section:**\n\n```markdown\n## [Original Section Title]\n\n[Original content preserved]\n\n### Research Insights\n\n**Best Practices:**\n- [Concrete recommendation 1]\n- [Concrete recommendation 2]\n\n**Performance Considerations:**\n- [Optimization opportunity]\n- [Benchmark or metric to target]\n\n**Implementation Details:**\n```[language]\n// Concrete code example from research\n```\n\n**Edge Cases:**\n- [Edge case 1 and how to handle]\n- [Edge case 2 and how to handle]\n\n**References:**\n- [Documentation URL 1]\n- [Documentation URL 2]\n```\n\n### 8. Add Enhancement Summary\n\nAt the top of the plan, add a summary section:\n\n```markdown\n## Enhancement Summary\n\n**Deepened on:** [Date]\n**Sections enhanced:** [Count]\n**Research agents used:** [List]\n\n### Key Improvements\n1. [Major improvement 1]\n2. [Major improvement 2]\n3. [Major improvement 3]\n\n### New Considerations Discovered\n- [Important finding 1]\n- [Important finding 2]\n```\n\n### 9. Update Plan File\n\n**Write the enhanced plan:**\n- Preserve original filename\n- Add `-deepened` suffix if user prefers a new file\n- Update any timestamps or metadata\n\n## Output Format\n\nUpdate the plan file in place (or if user requests a separate file, append `-deepened` after `-plan`, e.g., `2026-01-15-feat-auth-plan-deepened.md`).\n\n## Quality Checks\n\nBefore finalizing:\n- [ ] All original content preserved\n- [ ] Research insights clearly marked and attributed\n- [ ] Code examples are syntactically correct\n- [ ] Links are valid and relevant\n- [ ] No contradictions between sections\n- [ ] Enhancement summary accurately reflects changes\n\n## Post-Enhancement Options\n\nAfter writing the enhanced plan, use the **AskUserQuestion tool** to present these options:\n\n**Question:** \"Plan deepened at `[plan_path]`. What would you like to do next?\"\n\n**Options:**\n1. **View diff** - Show what was added/changed\n2. **Run `/technical_review`** - Get feedback from reviewers on enhanced plan\n3. **Start `/workflows:work`** - Begin implementing this enhanced plan\n4. **Deepen further** - Run another round of research on specific sections\n5. **Revert** - Restore original plan (if backup exists)\n\nBased on selection:\n- **View diff** ‚Üí Run `git diff [plan_path]` or show before/after\n- **`/technical_review`** ‚Üí Call the /technical_review command with the plan file path\n- **`/workflows:work`** ‚Üí Call the /workflows:work command with the plan file path\n- **Deepen further** ‚Üí Ask which sections need more research, then re-run those agents\n- **Revert** ‚Üí Restore from git or backup\n\n## Example Enhancement\n\n**Before (from /workflows:plan):**\n```markdown\n## Technical Approach\n\nUse React Query for data fetching with optimistic updates.\n```\n\n**After (from /workflows:deepen-plan):**\n```markdown\n## Technical Approach\n\nUse React Query for data fetching with optimistic updates.\n\n### Research Insights\n\n**Best Practices:**\n- Configure `staleTime` and `cacheTime` based on data freshness requirements\n- Use `queryKey` factories for consistent cache invalidation\n- Implement error boundaries around query-dependent components\n\n**Performance Considerations:**\n- Enable `refetchOnWindowFocus: false` for stable data to reduce unnecessary requests\n- Use `select` option to transform and memoize data at query level\n- Consider `placeholderData` for instant perceived loading\n\n**Implementation Details:**\n```typescript\n// Recommended query configuration\nconst queryClient = new QueryClient({\n  defaultOptions: {\n    queries: {\n      staleTime: 5 * 60 * 1000, // 5 minutes\n      retry: 2,\n      refetchOnWindowFocus: false,\n    },\n  },\n});\n```\n\n**Edge Cases:**\n- Handle race conditions with `cancelQueries` on component unmount\n- Implement retry logic for transient network failures\n- Consider offline support with `persistQueryClient`\n\n**References:**\n- https://tanstack.com/query/latest/docs/react/guides/optimistic-updates\n- https://tkdodo.eu/blog/practical-react-query\n```\n\nNEVER CODE! Just research and enhance the plan."
    },
    "workflows:work": {
      "description": "Execute work plans efficiently while maintaining quality and finishing features",
      "template": "# Work Plan Execution Command\n\nExecute a work plan efficiently while maintaining quality and finishing features.\n\n## Introduction\n\nThis command takes a work document (plan, specification, or todo file) and executes it systematically. The focus is on **shipping complete features** by understanding requirements quickly, following existing patterns, and maintaining quality throughout.\n\n## Input Document\n\n<input_document> #$ARGUMENTS </input_document>\n\n## Execution Workflow\n\n### Phase 1: Quick Start\n\n1. **Read Plan and Clarify**\n\n   - Read the work document completely\n   - Review any references or links provided in the plan\n   - If anything is unclear or ambiguous, ask clarifying questions now\n   - Get user approval to proceed\n   - **Do not skip this** - better to ask questions now than build the wrong thing\n\n2. **Setup Environment**\n\n   First, check the current branch:\n\n   ```bash\n   current_branch=$(git branch --show-current)\n   default_branch=$(git symbolic-ref refs/remotes/origin/HEAD 2>/dev/null | sed 's@^refs/remotes/origin/@@')\n\n   # Fallback if remote HEAD isn't set\n   if [ -z \"$default_branch\" ]; then\n     default_branch=$(git rev-parse --verify origin/main >/dev/null 2>&1 && echo \"main\" || echo \"master\")\n   fi\n   ```\n\n   **If already on a feature branch** (not the default branch):\n   - Ask: \"Continue working on `[current_branch]`, or create a new branch?\"\n   - If continuing, proceed to step 3\n   - If creating new, follow Option A or B below\n\n   **If on the default branch**, choose how to proceed:\n\n   **Option A: Create a new branch**\n   ```bash\n   git pull origin [default_branch]\n   git checkout -b feature-branch-name\n   ```\n   Use a meaningful name based on the work (e.g., `feat/user-authentication`, `fix/email-validation`).\n\n   **Option B: Use a worktree (recommended for parallel development)**\n   ```bash\n   skill: git-worktree\n   # The skill will create a new branch from the default branch in an isolated worktree\n   ```\n\n   **Option C: Continue on the default branch**\n   - Requires explicit user confirmation\n   - Only proceed after user explicitly says \"yes, commit to [default_branch]\"\n   - Never commit directly to the default branch without explicit permission\n\n   **Recommendation**: Use worktree if:\n   - You want to work on multiple features simultaneously\n   - You want to keep the default branch clean while experimenting\n   - You plan to switch between branches frequently\n\n3. **Create Todo List**\n   - Use TodoWrite to break plan into actionable tasks\n   - Include dependencies between tasks\n   - Prioritize based on what needs to be done first\n   - Include testing and quality check tasks\n   - Keep tasks specific and completable\n\n### Phase 2: Execute\n\n1. **Task Execution Loop**\n\n   For each task in priority order:\n\n   ```\n   while (tasks remain):\n     - Mark task as in_progress in TodoWrite\n     - Read any referenced files from the plan\n     - Look for similar patterns in codebase\n     - Implement following existing conventions\n     - Write tests for new functionality\n     - Run tests after changes\n     - Mark task as completed in TodoWrite\n     - Mark off the corresponding checkbox in the plan file ([ ] ‚Üí [x])\n     - Evaluate for incremental commit (see below)\n   ```\n\n   **IMPORTANT**: Always update the original plan document by checking off completed items. Use the Edit tool to change `- [ ]` to `- [x]` for each task you finish. This keeps the plan as a living document showing progress and ensures no checkboxes are left unchecked.\n\n2. **Incremental Commits**\n\n   After completing each task, evaluate whether to create an incremental commit:\n\n   | Commit when... | Don't commit when... |\n   |----------------|---------------------|\n   | Logical unit complete (model, service, component) | Small part of a larger unit |\n   | Tests pass + meaningful progress | Tests failing |\n   | About to switch contexts (backend ‚Üí frontend) | Purely scaffolding with no behavior |\n   | About to attempt risky/uncertain changes | Would need a \"WIP\" commit message |\n\n   **Heuristic:** \"Can I write a commit message that describes a complete, valuable change? If yes, commit. If the message would be 'WIP' or 'partial X', wait.\"\n\n   **Commit workflow:**\n   ```bash\n   # 1. Verify tests pass (use project's test command)\n   # Examples: bin/rails test, npm test, pytest, go test, etc.\n\n   # 2. Stage only files related to this logical unit (not `git add .`)\n   git add <files related to this logical unit>\n\n   # 3. Commit with conventional message\n   git commit -m \"feat(scope): description of this unit\"\n   ```\n\n   **Handling merge conflicts:** If conflicts arise during rebasing or merging, resolve them immediately. Incremental commits make conflict resolution easier since each commit is small and focused.\n\n   **Note:** Incremental commits use clean conventional messages without attribution footers. The final Phase 4 commit/PR includes the full attribution.\n\n3. **Follow Existing Patterns**\n\n   - The plan should reference similar code - read those files first\n   - Match naming conventions exactly\n   - Reuse existing components where possible\n   - Follow project coding standards (see CLAUDE.md)\n   - When in doubt, grep for similar implementations\n\n4. **Test Continuously**\n\n   - Run relevant tests after each significant change\n   - Don't wait until the end to test\n   - Fix failures immediately\n   - Add new tests for new functionality\n\n5. **Figma Design Sync** (if applicable)\n\n   For UI work with Figma designs:\n\n   - Implement components following design specs\n   - Use figma-design-sync agent iteratively to compare\n   - Fix visual differences identified\n   - Repeat until implementation matches design\n\n6. **Track Progress**\n   - Keep TodoWrite updated as you complete tasks\n   - Note any blockers or unexpected discoveries\n   - Create new tasks if scope expands\n   - Keep user informed of major milestones\n\n### Phase 3: Quality Check\n\n1. **Run Core Quality Checks**\n\n   Always run before submitting:\n\n   ```bash\n   # Run full test suite (use project's test command)\n   # Examples: bin/rails test, npm test, pytest, go test, etc.\n\n   # Run linting (per CLAUDE.md)\n   # Use linting-agent before pushing to origin\n   ```\n\n2. **Consider Reviewer Agents** (Optional)\n\n   Use for complex, risky, or large changes. Read agents from `compound-engineering.local.md` frontmatter (`review_agents`). If no settings file, invoke the `setup` skill to create one.\n\n   Run configured agents in parallel with Task tool. Present findings and address critical issues.\n\n3. **Final Validation**\n   - All TodoWrite tasks marked completed\n   - All tests pass\n   - Linting passes\n   - Code follows existing patterns\n   - Figma designs match (if applicable)\n   - No console errors or warnings\n\n4. **Prepare Operational Validation Plan** (REQUIRED)\n   - Add a `## Post-Deploy Monitoring & Validation` section to the PR description for every change.\n   - Include concrete:\n     - Log queries/search terms\n     - Metrics or dashboards to watch\n     - Expected healthy signals\n     - Failure signals and rollback/mitigation trigger\n     - Validation window and owner\n   - If there is truly no production/runtime impact, still include the section with: `No additional operational monitoring required` and a one-line reason.\n\n### Phase 4: Ship It\n\n1. **Create Commit**\n\n   ```bash\n   git add .\n   git status  # Review what's being committed\n   git diff --staged  # Check the changes\n\n   # Commit with conventional format\n   git commit -m \"$(cat <<'EOF'\n   feat(scope): description of what and why\n\n   Brief explanation if needed.\n\n   ü§ñ Generated with [Claude Code](https://claude.com/claude-code)\n\n   Co-Authored-By: Claude <noreply@anthropic.com>\n   EOF\n   )\"\n   ```\n\n2. **Capture and Upload Screenshots for UI Changes** (REQUIRED for any UI work)\n\n   For **any** design changes, new views, or UI modifications, you MUST capture and upload screenshots:\n\n   **Step 1: Start dev server** (if not running)\n   ```bash\n   bin/dev  # Run in background\n   ```\n\n   **Step 2: Capture screenshots with agent-browser CLI**\n   ```bash\n   agent-browser open http://localhost:3000/[route]\n   agent-browser snapshot -i\n   agent-browser screenshot output.png\n   ```\n   See the `agent-browser` skill for detailed usage.\n\n   **Step 3: Upload using imgup skill**\n   ```bash\n   skill: imgup\n   # Then upload each screenshot:\n   imgup -h pixhost screenshot.png  # pixhost works without API key\n   # Alternative hosts: catbox, imagebin, beeimg\n   ```\n\n   **What to capture:**\n   - **New screens**: Screenshot of the new UI\n   - **Modified screens**: Before AND after screenshots\n   - **Design implementation**: Screenshot showing Figma design match\n\n   **IMPORTANT**: Always include uploaded image URLs in PR description. This provides visual context for reviewers and documents the change.\n\n3. **Create Pull Request**\n\n   ```bash\n   git push -u origin feature-branch-name\n\n   gh pr create --title \"Feature: [Description]\" --body \"$(cat <<'EOF'\n   ## Summary\n   - What was built\n   - Why it was needed\n   - Key decisions made\n\n   ## Testing\n   - Tests added/modified\n   - Manual testing performed\n\n   ## Post-Deploy Monitoring & Validation\n   - **What to monitor/search**\n     - Logs:\n     - Metrics/Dashboards:\n   - **Validation checks (queries/commands)**\n     - `command or query here`\n   - **Expected healthy behavior**\n     - Expected signal(s)\n   - **Failure signal(s) / rollback trigger**\n     - Trigger + immediate action\n   - **Validation window & owner**\n     - Window:\n     - Owner:\n   - **If no operational impact**\n     - `No additional operational monitoring required: <reason>`\n\n   ## Before / After Screenshots\n   | Before | After |\n   |--------|-------|\n   | ![before](URL) | ![after](URL) |\n\n   ## Figma Design\n   [Link if applicable]\n\n   ---\n\n   [![Compound Engineered](https://img.shields.io/badge/Compound-Engineered-6366f1)](https://github.com/EveryInc/compound-engineering-plugin) ü§ñ Generated with [Claude Code](https://claude.com/claude-code)\n   EOF\n   )\"\n   ```\n\n4. **Notify User**\n   - Summarize what was completed\n   - Link to PR\n   - Note any follow-up work needed\n   - Suggest next steps if applicable\n\n---\n\n## Swarm Mode (Optional)\n\nFor complex plans with multiple independent workstreams, enable swarm mode for parallel execution with coordinated agents.\n\n### When to Use Swarm Mode\n\n| Use Swarm Mode when... | Use Standard Mode when... |\n|------------------------|---------------------------|\n| Plan has 5+ independent tasks | Plan is linear/sequential |\n| Multiple specialists needed (review + test + implement) | Single-focus work |\n| Want maximum parallelism | Simpler mental model preferred |\n| Large feature with clear phases | Small feature or bug fix |\n\n### Enabling Swarm Mode\n\nTo trigger swarm execution, say:\n\n> \"Make a Task list and launch an army of agent swarm subagents to build the plan\"\n\nOr explicitly request: \"Use swarm mode for this work\"\n\n### Swarm Workflow\n\nWhen swarm mode is enabled, the workflow changes:\n\n1. **Create Team**\n   ```\n   Teammate({ operation: \"spawnTeam\", team_name: \"work-{timestamp}\" })\n   ```\n\n2. **Create Task List with Dependencies**\n   - Parse plan into TaskCreate items\n   - Set up blockedBy relationships for sequential dependencies\n   - Independent tasks have no blockers (can run in parallel)\n\n3. **Spawn Specialized Teammates**\n   ```\n   Task({\n     team_name: \"work-{timestamp}\",\n     name: \"implementer\",\n     subagent_type: \"general-purpose\",\n     prompt: \"Claim implementation tasks, execute, mark complete\",\n     run_in_background: true\n   })\n\n   Task({\n     team_name: \"work-{timestamp}\",\n     name: \"tester\",\n     subagent_type: \"general-purpose\",\n     prompt: \"Claim testing tasks, run tests, mark complete\",\n     run_in_background: true\n   })\n   ```\n\n4. **Coordinate and Monitor**\n   - Team lead monitors task completion\n   - Spawn additional workers as phases unblock\n   - Handle plan approval if required\n\n5. **Cleanup**\n   ```\n   Teammate({ operation: \"requestShutdown\", target_agent_id: \"implementer\" })\n   Teammate({ operation: \"requestShutdown\", target_agent_id: \"tester\" })\n   Teammate({ operation: \"cleanup\" })\n   ```\n\nSee the `orchestrating-swarms` skill for detailed swarm patterns and best practices.\n\n---\n\n## Key Principles\n\n### Start Fast, Execute Faster\n\n- Get clarification once at the start, then execute\n- Don't wait for perfect understanding - ask questions and move\n- The goal is to **finish the feature**, not create perfect process\n\n### The Plan is Your Guide\n\n- Work documents should reference similar code and patterns\n- Load those references and follow them\n- Don't reinvent - match what exists\n\n### Test As You Go\n\n- Run tests after each change, not at the end\n- Fix failures immediately\n- Continuous testing prevents big surprises\n\n### Quality is Built In\n\n- Follow existing patterns\n- Write tests for new code\n- Run linting before pushing\n- Use reviewer agents for complex/risky changes only\n\n### Ship Complete Features\n\n- Mark all tasks completed before moving on\n- Don't leave features 80% done\n- A finished feature that ships beats a perfect feature that doesn't\n\n## Quality Checklist\n\nBefore creating PR, verify:\n\n- [ ] All clarifying questions asked and answered\n- [ ] All TodoWrite tasks marked completed\n- [ ] Tests pass (run project's test command)\n- [ ] Linting passes (use linting-agent)\n- [ ] Code follows existing patterns\n- [ ] Figma designs match implementation (if applicable)\n- [ ] Before/after screenshots captured and uploaded (for UI changes)\n- [ ] Commit messages follow conventional format\n- [ ] PR description includes Post-Deploy Monitoring & Validation section (or explicit no-impact rationale)\n- [ ] PR description includes summary, testing notes, and screenshots\n- [ ] PR description includes Compound Engineered badge\n\n## When to Use Reviewer Agents\n\n**Don't use by default.** Use reviewer agents only when:\n\n- Large refactor affecting many files (10+)\n- Security-sensitive changes (authentication, permissions, data access)\n- Performance-critical code paths\n- Complex algorithms or business logic\n- User explicitly requests thorough review\n\nFor most features: tests + linting + following patterns is sufficient.\n\n## Common Pitfalls to Avoid\n\n- **Analysis paralysis** - Don't overthink, read the plan and execute\n- **Skipping clarifying questions** - Ask now, not after building wrong thing\n- **Ignoring plan references** - The plan has links for a reason\n- **Testing at the end** - Test continuously or suffer later\n- **Forgetting TodoWrite** - Track progress or lose track of what's done\n- **80% done syndrome** - Finish the feature, don't move on early\n- **Over-reviewing simple changes** - Save reviewer agents for complex work"
    },
    "workflows:compound": {
      "description": "Document a recently solved problem to compound your team's knowledge",
      "template": "# /compound\n\nCoordinate multiple subagents working in parallel to document a recently solved problem.\n\n## Purpose\n\nCaptures problem solutions while context is fresh, creating structured documentation in `docs/solutions/` with YAML frontmatter for searchability and future reference. Uses parallel subagents for maximum efficiency.\n\n**Why \"compound\"?** Each documented solution compounds your team's knowledge. The first time you solve a problem takes research. Document it, and the next occurrence takes minutes. Knowledge compounds.\n\n## Usage\n\n```bash\n/workflows:compound                    # Document the most recent fix\n/workflows:compound [brief context]    # Provide additional context hint\n```\n\n## Execution Strategy: Two-Phase Orchestration\n\n<critical_requirement>\n**Only ONE file gets written - the final documentation.**\n\nPhase 1 subagents return TEXT DATA to the orchestrator. They must NOT use Write, Edit, or create any files. Only the orchestrator (Phase 2) writes the final documentation file.\n</critical_requirement>\n\n### Phase 1: Parallel Research\n\n<parallel_tasks>\n\nLaunch these subagents IN PARALLEL. Each returns text data to the orchestrator.\n\n#### 1. **Context Analyzer**\n   - Extracts conversation history\n   - Identifies problem type, component, symptoms\n   - Validates against schema\n   - Returns: YAML frontmatter skeleton\n\n#### 2. **Solution Extractor**\n   - Analyzes all investigation steps\n   - Identifies root cause\n   - Extracts working solution with code examples\n   - Returns: Solution content block\n\n#### 3. **Related Docs Finder**\n   - Searches `docs/solutions/` for related documentation\n   - Identifies cross-references and links\n   - Finds related GitHub issues\n   - Returns: Links and relationships\n\n#### 4. **Prevention Strategist**\n   - Develops prevention strategies\n   - Creates best practices guidance\n   - Generates test cases if applicable\n   - Returns: Prevention/testing content\n\n#### 5. **Category Classifier**\n   - Determines optimal `docs/solutions/` category\n   - Validates category against schema\n   - Suggests filename based on slug\n   - Returns: Final path and filename\n\n</parallel_tasks>\n\n### Phase 2: Assembly & Write\n\n<sequential_tasks>\n\n**WAIT for all Phase 1 subagents to complete before proceeding.**\n\nThe orchestrating agent (main conversation) performs these steps:\n\n1. Collect all text results from Phase 1 subagents\n2. Assemble complete markdown file from the collected pieces\n3. Validate YAML frontmatter against schema\n4. Create directory if needed: `mkdir -p docs/solutions/[category]/`\n5. Write the SINGLE final file: `docs/solutions/[category]/[filename].md`\n\n</sequential_tasks>\n\n### Phase 3: Optional Enhancement\n\n**WAIT for Phase 2 to complete before proceeding.**\n\n<parallel_tasks>\n\nBased on problem type, optionally invoke specialized agents to review the documentation:\n\n- **performance_issue** ‚Üí `performance-oracle`\n- **security_issue** ‚Üí `security-sentinel`\n- **database_issue** ‚Üí `data-integrity-guardian`\n- **test_failure** ‚Üí `cora-test-reviewer`\n- Any code-heavy issue ‚Üí `kieran-rails-reviewer` + `code-simplicity-reviewer`\n\n</parallel_tasks>\n\n## What It Captures\n\n- **Problem symptom**: Exact error messages, observable behavior\n- **Investigation steps tried**: What didn't work and why\n- **Root cause analysis**: Technical explanation\n- **Working solution**: Step-by-step fix with code examples\n- **Prevention strategies**: How to avoid in future\n- **Cross-references**: Links to related issues and docs\n\n## Preconditions\n\n<preconditions enforcement=\"advisory\">\n  <check condition=\"problem_solved\">\n    Problem has been solved (not in-progress)\n  </check>\n  <check condition=\"solution_verified\">\n    Solution has been verified working\n  </check>\n  <check condition=\"non_trivial\">\n    Non-trivial problem (not simple typo or obvious error)\n  </check>\n</preconditions>\n\n## What It Creates\n\n**Organized documentation:**\n\n- File: `docs/solutions/[category]/[filename].md`\n\n**Categories auto-detected from problem:**\n\n- build-errors/\n- test-failures/\n- runtime-errors/\n- performance-issues/\n- database-issues/\n- security-issues/\n- ui-bugs/\n- integration-issues/\n- logic-errors/\n\n## Common Mistakes to Avoid\n\n| ‚ùå Wrong | ‚úÖ Correct |\n|----------|-----------|\n| Subagents write files like `context-analysis.md`, `solution-draft.md` | Subagents return text data; orchestrator writes one final file |\n| Research and assembly run in parallel | Research completes ‚Üí then assembly runs |\n| Multiple files created during workflow | Single file: `docs/solutions/[category]/[filename].md` |\n\n## Success Output\n\n```\n‚úì Documentation complete\n\nSubagent Results:\n  ‚úì Context Analyzer: Identified performance_issue in brief_system\n  ‚úì Solution Extractor: 3 code fixes\n  ‚úì Related Docs Finder: 2 related issues\n  ‚úì Prevention Strategist: Prevention strategies, test suggestions\n  ‚úì Category Classifier: `performance-issues`\n\nSpecialized Agent Reviews (Auto-Triggered):\n  ‚úì performance-oracle: Validated query optimization approach\n  ‚úì kieran-rails-reviewer: Code examples meet Rails standards\n  ‚úì code-simplicity-reviewer: Solution is appropriately minimal\n  ‚úì every-style-editor: Documentation style verified\n\nFile created:\n- docs/solutions/performance-issues/n-plus-one-brief-generation.md\n\nThis documentation will be searchable for future reference when similar\nissues occur in the Email Processing or Brief System modules.\n\nWhat's next?\n1. Continue workflow (recommended)\n2. Link related documentation\n3. Update other references\n4. View documentation\n5. Other\n```\n\n## The Compounding Philosophy\n\nThis creates a compounding knowledge system:\n\n1. First time you solve \"N+1 query in brief generation\" ‚Üí Research (30 min)\n2. Document the solution ‚Üí docs/solutions/performance-issues/n-plus-one-briefs.md (5 min)\n3. Next time similar issue occurs ‚Üí Quick lookup (2 min)\n4. Knowledge compounds ‚Üí Team gets smarter\n\nThe feedback loop:\n\n```\nBuild ‚Üí Test ‚Üí Find Issue ‚Üí Research ‚Üí Improve ‚Üí Document ‚Üí Validate ‚Üí Deploy\n    ‚Üë                                                                      ‚Üì\n    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n**Each unit of engineering work should make subsequent units of work easier‚Äînot harder.**\n\n## Auto-Invoke\n\n<auto_invoke> <trigger_phrases> - \"that worked\" - \"it's fixed\" - \"working now\" - \"problem solved\" </trigger_phrases>\n\n<manual_override> Use /workflows:compound [context] to document immediately without waiting for auto-detection. </manual_override> </auto_invoke>\n\n## Routes To\n\n`compound-docs` skill\n\n## Applicable Specialized Agents\n\nBased on problem type, these agents can enhance documentation:\n\n### Code Quality & Review\n- **kieran-rails-reviewer**: Reviews code examples for Rails best practices\n- **code-simplicity-reviewer**: Ensures solution code is minimal and clear\n- **pattern-recognition-specialist**: Identifies anti-patterns or repeating issues\n\n### Specific Domain Experts\n- **performance-oracle**: Analyzes performance_issue category solutions\n- **security-sentinel**: Reviews security_issue solutions for vulnerabilities\n- **cora-test-reviewer**: Creates test cases for prevention strategies\n- **data-integrity-guardian**: Reviews database_issue migrations and queries\n\n### Enhancement & Documentation\n- **best-practices-researcher**: Enriches solution with industry best practices\n- **every-style-editor**: Reviews documentation style and clarity\n- **framework-docs-researcher**: Links to Rails/gem documentation references\n\n### When to Invoke\n- **Auto-triggered** (optional): Agents can run post-documentation for enhancement\n- **Manual trigger**: User can invoke agents after /workflows:compound completes for deeper review\n- **Customize agents**: Edit `compound-engineering.local.md` or invoke the `setup` skill to configure which review agents are used across all workflows\n\n## Related Commands\n\n- `/research [topic]` - Deep investigation (searches docs/solutions/ for patterns)\n- `/workflows:plan` - Planning workflow (references documented solutions)"
    },
    "workflows:plan": {
      "description": "Transform feature descriptions into well-structured project plans following conventions",
      "template": "# Create a plan for a new feature or bug fix\n\n## Introduction\n\n**Note: The current year is 2026.** Use this when dating plans and searching for recent documentation.\n\nTransform feature descriptions, bug reports, or improvement ideas into well-structured markdown files issues that follow project conventions and best practices. This command provides flexible detail levels to match your needs.\n\n## Feature Description\n\n<feature_description> #$ARGUMENTS </feature_description>\n\n**If the feature description above is empty, ask the user:** \"What would you like to plan? Please describe the feature, bug fix, or improvement you have in mind.\"\n\nDo not proceed until you have a clear feature description from the user.\n\n### 0. Idea Refinement\n\n**Check for brainstorm output first:**\n\nBefore asking questions, look for recent brainstorm documents in `docs/brainstorms/` that match this feature:\n\n```bash\nls -la docs/brainstorms/*.md 2>/dev/null | head -10\n```\n\n**Relevance criteria:** A brainstorm is relevant if:\n- The topic (from filename or YAML frontmatter) semantically matches the feature description\n- Created within the last 14 days\n- If multiple candidates match, use the most recent one\n\n**If a relevant brainstorm exists:**\n1. Read the brainstorm document\n2. Announce: \"Found brainstorm from [date]: [topic]. Using as context for planning.\"\n3. Extract key decisions, chosen approach, and open questions\n4. **Skip the idea refinement questions below** - the brainstorm already answered WHAT to build\n5. Use brainstorm decisions as input to the research phase\n\n**If multiple brainstorms could match:**\nUse **AskUserQuestion tool** to ask which brainstorm to use, or whether to proceed without one.\n\n**If no brainstorm found (or not relevant), run idea refinement:**\n\nRefine the idea through collaborative dialogue using the **AskUserQuestion tool**:\n\n- Ask questions one at a time to understand the idea fully\n- Prefer multiple choice questions when natural options exist\n- Focus on understanding: purpose, constraints and success criteria\n- Continue until the idea is clear OR user says \"proceed\"\n\n**Gather signals for research decision.** During refinement, note:\n\n- **User's familiarity**: Do they know the codebase patterns? Are they pointing to examples?\n- **User's intent**: Speed vs thoroughness? Exploration vs execution?\n- **Topic risk**: Security, payments, external APIs warrant more caution\n- **Uncertainty level**: Is the approach clear or open-ended?\n\n**Skip option:** If the feature description is already detailed, offer:\n\"Your description is clear. Should I proceed with research, or would you like to refine it further?\"\n\n## Main Tasks\n\n### 1. Local Research (Always Runs - Parallel)\n\n<thinking>\nFirst, I need to understand the project's conventions, existing patterns, and any documented learnings. This is fast and local - it informs whether external research is needed.\n</thinking>\n\nRun these agents **in parallel** to gather local context:\n\n- Task repo-research-analyst(feature_description)\n- Task learnings-researcher(feature_description)\n\n**What to look for:**\n- **Repo research:** existing patterns, CLAUDE.md guidance, technology familiarity, pattern consistency\n- **Learnings:** documented solutions in `docs/solutions/` that might apply (gotchas, patterns, lessons learned)\n\nThese findings inform the next step.\n\n### 1.5. Research Decision\n\nBased on signals from Step 0 and findings from Step 1, decide on external research.\n\n**High-risk topics ‚Üí always research.** Security, payments, external APIs, data privacy. The cost of missing something is too high. This takes precedence over speed signals.\n\n**Strong local context ‚Üí skip external research.** Codebase has good patterns, CLAUDE.md has guidance, user knows what they want. External research adds little value.\n\n**Uncertainty or unfamiliar territory ‚Üí research.** User is exploring, codebase has no examples, new technology. External perspective is valuable.\n\n**Announce the decision and proceed.** Brief explanation, then continue. User can redirect if needed.\n\nExamples:\n- \"Your codebase has solid patterns for this. Proceeding without external research.\"\n- \"This involves payment processing, so I'll research current best practices first.\"\n\n### 1.5b. External Research (Conditional)\n\n**Only run if Step 1.5 indicates external research is valuable.**\n\nRun these agents in parallel:\n\n- Task best-practices-researcher(feature_description)\n- Task framework-docs-researcher(feature_description)\n\n### 1.6. Consolidate Research\n\nAfter all research steps complete, consolidate findings:\n\n- Document relevant file paths from repo research (e.g., `app/services/example_service.rb:42`)\n- **Include relevant institutional learnings** from `docs/solutions/` (key insights, gotchas to avoid)\n- Note external documentation URLs and best practices (if external research was done)\n- List related issues or PRs discovered\n- Capture CLAUDE.md conventions\n\n**Optional validation:** Briefly summarize findings and ask if anything looks off or missing before proceeding to planning.\n\n### 2. Issue Planning & Structure\n\n<thinking>\nThink like a product manager - what would make this issue clear and actionable? Consider multiple perspectives\n</thinking>\n\n**Title & Categorization:**\n\n- [ ] Draft clear, searchable issue title using conventional format (e.g., `feat: Add user authentication`, `fix: Cart total calculation`)\n- [ ] Determine issue type: enhancement, bug, refactor\n- [ ] Convert title to filename: add today's date prefix, strip prefix colon, kebab-case, add `-plan` suffix\n  - Example: `feat: Add User Authentication` ‚Üí `2026-01-21-feat-add-user-authentication-plan.md`\n  - Keep it descriptive (3-5 words after prefix) so plans are findable by context\n\n**Stakeholder Analysis:**\n\n- [ ] Identify who will be affected by this issue (end users, developers, operations)\n- [ ] Consider implementation complexity and required expertise\n\n**Content Planning:**\n\n- [ ] Choose appropriate detail level based on issue complexity and audience\n- [ ] List all necessary sections for the chosen template\n- [ ] Gather supporting materials (error logs, screenshots, design mockups)\n- [ ] Prepare code examples or reproduction steps if applicable, name the mock filenames in the lists\n\n### 3. SpecFlow Analysis\n\nAfter planning the issue structure, run SpecFlow Analyzer to validate and refine the feature specification:\n\n- Task spec-flow-analyzer(feature_description, research_findings)\n\n**SpecFlow Analyzer Output:**\n\n- [ ] Review SpecFlow analysis results\n- [ ] Incorporate any identified gaps or edge cases into the issue\n- [ ] Update acceptance criteria based on SpecFlow findings\n\n### 4. Choose Implementation Detail Level\n\nSelect how comprehensive you want the issue to be, simpler is mostly better.\n\n#### üìÑ MINIMAL (Quick Issue)\n\n**Best for:** Simple bugs, small improvements, clear features\n\n**Includes:**\n\n- Problem statement or feature description\n- Basic acceptance criteria\n- Essential context only\n\n**Structure:**\n\n````markdown\n---\ntitle: [Issue Title]\ntype: [feat|fix|refactor]\ndate: YYYY-MM-DD\n---\n\n# [Issue Title]\n\n[Brief problem/feature description]\n\n## Acceptance Criteria\n\n- [ ] Core requirement 1\n- [ ] Core requirement 2\n\n## Context\n\n[Any critical information]\n\n## MVP\n\n### test.rb\n\n```ruby\nclass Test\n  def initialize\n    @name = \"test\"\n  end\nend\n```\n\n## References\n\n- Related issue: #[issue_number]\n- Documentation: [relevant_docs_url]\n````\n\n#### üìã MORE (Standard Issue)\n\n**Best for:** Most features, complex bugs, team collaboration\n\n**Includes everything from MINIMAL plus:**\n\n- Detailed background and motivation\n- Technical considerations\n- Success metrics\n- Dependencies and risks\n- Basic implementation suggestions\n\n**Structure:**\n\n```markdown\n---\ntitle: [Issue Title]\ntype: [feat|fix|refactor]\ndate: YYYY-MM-DD\n---\n\n# [Issue Title]\n\n## Overview\n\n[Comprehensive description]\n\n## Problem Statement / Motivation\n\n[Why this matters]\n\n## Proposed Solution\n\n[High-level approach]\n\n## Technical Considerations\n\n- Architecture impacts\n- Performance implications\n- Security considerations\n\n## Acceptance Criteria\n\n- [ ] Detailed requirement 1\n- [ ] Detailed requirement 2\n- [ ] Testing requirements\n\n## Success Metrics\n\n[How we measure success]\n\n## Dependencies & Risks\n\n[What could block or complicate this]\n\n## References & Research\n\n- Similar implementations: [file_path:line_number]\n- Best practices: [documentation_url]\n- Related PRs: #[pr_number]\n```\n\n#### üìö A LOT (Comprehensive Issue)\n\n**Best for:** Major features, architectural changes, complex integrations\n\n**Includes everything from MORE plus:**\n\n- Detailed implementation plan with phases\n- Alternative approaches considered\n- Extensive technical specifications\n- Resource requirements and timeline\n- Future considerations and extensibility\n- Risk mitigation strategies\n- Documentation requirements\n\n**Structure:**\n\n```markdown\n---\ntitle: [Issue Title]\ntype: [feat|fix|refactor]\ndate: YYYY-MM-DD\n---\n\n# [Issue Title]\n\n## Overview\n\n[Executive summary]\n\n## Problem Statement\n\n[Detailed problem analysis]\n\n## Proposed Solution\n\n[Comprehensive solution design]\n\n## Technical Approach\n\n### Architecture\n\n[Detailed technical design]\n\n### Implementation Phases\n\n#### Phase 1: [Foundation]\n\n- Tasks and deliverables\n- Success criteria\n- Estimated effort\n\n#### Phase 2: [Core Implementation]\n\n- Tasks and deliverables\n- Success criteria\n- Estimated effort\n\n#### Phase 3: [Polish & Optimization]\n\n- Tasks and deliverables\n- Success criteria\n- Estimated effort\n\n## Alternative Approaches Considered\n\n[Other solutions evaluated and why rejected]\n\n## Acceptance Criteria\n\n### Functional Requirements\n\n- [ ] Detailed functional criteria\n\n### Non-Functional Requirements\n\n- [ ] Performance targets\n- [ ] Security requirements\n- [ ] Accessibility standards\n\n### Quality Gates\n\n- [ ] Test coverage requirements\n- [ ] Documentation completeness\n- [ ] Code review approval\n\n## Success Metrics\n\n[Detailed KPIs and measurement methods]\n\n## Dependencies & Prerequisites\n\n[Detailed dependency analysis]\n\n## Risk Analysis & Mitigation\n\n[Comprehensive risk assessment]\n\n## Resource Requirements\n\n[Team, time, infrastructure needs]\n\n## Future Considerations\n\n[Extensibility and long-term vision]\n\n## Documentation Plan\n\n[What docs need updating]\n\n## References & Research\n\n### Internal References\n\n- Architecture decisions: [file_path:line_number]\n- Similar features: [file_path:line_number]\n- Configuration: [file_path:line_number]\n\n### External References\n\n- Framework documentation: [url]\n- Best practices guide: [url]\n- Industry standards: [url]\n\n### Related Work\n\n- Previous PRs: #[pr_numbers]\n- Related issues: #[issue_numbers]\n- Design documents: [links]\n```\n\n### 5. Issue Creation & Formatting\n\n<thinking>\nApply best practices for clarity and actionability, making the issue easy to scan and understand\n</thinking>\n\n**Content Formatting:**\n\n- [ ] Use clear, descriptive headings with proper hierarchy (##, ###)\n- [ ] Include code examples in triple backticks with language syntax highlighting\n- [ ] Add screenshots/mockups if UI-related (drag & drop or use image hosting)\n- [ ] Use task lists (- [ ]) for trackable items that can be checked off\n- [ ] Add collapsible sections for lengthy logs or optional details using `<details>` tags\n- [ ] Apply appropriate emoji for visual scanning (üêõ bug, ‚ú® feature, üìö docs, ‚ôªÔ∏è refactor)\n\n**Cross-Referencing:**\n\n- [ ] Link to related issues/PRs using #number format\n- [ ] Reference specific commits with SHA hashes when relevant\n- [ ] Link to code using GitHub's permalink feature (press 'y' for permanent link)\n- [ ] Mention relevant team members with @username if needed\n- [ ] Add links to external resources with descriptive text\n\n**Code & Examples:**\n\n````markdown\n# Good example with syntax highlighting and line references\n\n\n```ruby\n# app/services/user_service.rb:42\ndef process_user(user)\n\n# Implementation here\n\nend\n```\n\n# Collapsible error logs\n\n<details>\n<summary>Full error stacktrace</summary>\n\n`Error details here...`\n\n</details>\n````\n\n**AI-Era Considerations:**\n\n- [ ] Account for accelerated development with AI pair programming\n- [ ] Include prompts or instructions that worked well during research\n- [ ] Note which AI tools were used for initial exploration (Claude, Copilot, etc.)\n- [ ] Emphasize comprehensive testing given rapid implementation\n- [ ] Document any AI-generated code that needs human review\n\n### 6. Final Review & Submission\n\n**Pre-submission Checklist:**\n\n- [ ] Title is searchable and descriptive\n- [ ] Labels accurately categorize the issue\n- [ ] All template sections are complete\n- [ ] Links and references are working\n- [ ] Acceptance criteria are measurable\n- [ ] Add names of files in pseudo code examples and todo lists\n- [ ] Add an ERD mermaid diagram if applicable for new model changes\n\n## Output Format\n\n**Filename:** Use the date and kebab-case filename from Step 2 Title & Categorization.\n\n```\ndocs/plans/YYYY-MM-DD-<type>-<descriptive-name>-plan.md\n```\n\nExamples:\n- ‚úÖ `docs/plans/2026-01-15-feat-user-authentication-flow-plan.md`\n- ‚úÖ `docs/plans/2026-02-03-fix-checkout-race-condition-plan.md`\n- ‚úÖ `docs/plans/2026-03-10-refactor-api-client-extraction-plan.md`\n- ‚ùå `docs/plans/2026-01-15-feat-thing-plan.md` (not descriptive - what \"thing\"?)\n- ‚ùå `docs/plans/2026-01-15-feat-new-feature-plan.md` (too vague - what feature?)\n- ‚ùå `docs/plans/2026-01-15-feat: user auth-plan.md` (invalid characters - colon and space)\n- ‚ùå `docs/plans/feat-user-auth-plan.md` (missing date prefix)\n\n## Post-Generation Options\n\nAfter writing the plan file, use the **AskUserQuestion tool** to present these options:\n\n**Question:** \"Plan ready at `docs/plans/YYYY-MM-DD-<type>-<name>-plan.md`. What would you like to do next?\"\n\n**Options:**\n1. **Open plan in editor** - Open the plan file for review\n2. **Run `/deepen-plan`** - Enhance each section with parallel research agents (best practices, performance, UI)\n3. **Run `/technical_review`** - Technical feedback from code-focused reviewers (DHH, Kieran, Simplicity)\n4. **Review and refine** - Improve the document through structured self-review\n5. **Start `/workflows:work`** - Begin implementing this plan locally\n6. **Start `/workflows:work` on remote** - Begin implementing in Claude Code on the web (use `&` to run in background)\n7. **Create Issue** - Create issue in project tracker (GitHub/Linear)\n\nBased on selection:\n- **Open plan in editor** ‚Üí Run `open docs/plans/<plan_filename>.md` to open the file in the user's default editor\n- **`/deepen-plan`** ‚Üí Call the /deepen-plan command with the plan file path to enhance with research\n- **`/technical_review`** ‚Üí Call the /technical_review command with the plan file path\n- **Review and refine** ‚Üí Load `document-review` skill.\n- **`/workflows:work`** ‚Üí Call the /workflows:work command with the plan file path\n- **`/workflows:work` on remote** ‚Üí Run `/workflows:work docs/plans/<plan_filename>.md &` to start work in background for Claude Code web\n- **Create Issue** ‚Üí See \"Issue Creation\" section below\n- **Other** (automatically provided) ‚Üí Accept free text for rework or specific changes\n\n**Note:** If running `/workflows:plan` with ultrathink enabled, automatically run `/deepen-plan` after plan creation for maximum depth and grounding.\n\nLoop back to options after Simplify or Other changes until user selects `/workflows:work` or `/technical_review`.\n\n## Issue Creation\n\nWhen user selects \"Create Issue\", detect their project tracker from CLAUDE.md:\n\n1. **Check for tracker preference** in user's CLAUDE.md (global or project):\n   - Look for `project_tracker: github` or `project_tracker: linear`\n   - Or look for mentions of \"GitHub Issues\" or \"Linear\" in their workflow section\n\n2. **If GitHub:**\n\n   Use the title and type from Step 2 (already in context - no need to re-read the file):\n\n   ```bash\n   gh issue create --title \"<type>: <title>\" --body-file <plan_path>\n   ```\n\n3. **If Linear:**\n\n   ```bash\n   linear issue create --title \"<title>\" --description \"$(cat <plan_path>)\"\n   ```\n\n4. **If no tracker configured:**\n   Ask user: \"Which project tracker do you use? (GitHub/Linear/Other)\"\n   - Suggest adding `project_tracker: github` or `project_tracker: linear` to their CLAUDE.md\n\n5. **After creation:**\n   - Display the issue URL\n   - Ask if they want to proceed to `/workflows:work` or `/technical_review`\n\nNEVER CODE! Just research and write the plan."
    },
    "workflows:review": {
      "description": "Perform exhaustive code reviews using multi-agent analysis, ultra-thinking, and worktrees",
      "template": "# Review Command\n\n<command_purpose> Perform exhaustive code reviews using multi-agent analysis, ultra-thinking, and Git worktrees for deep local inspection. </command_purpose>\n\n## Introduction\n\n<role>Senior Code Review Architect with expertise in security, performance, architecture, and quality assurance</role>\n\n## Prerequisites\n\n<requirements>\n- Git repository with GitHub CLI (`gh`) installed and authenticated\n- Clean main/master branch\n- Proper permissions to create worktrees and access the repository\n- For document reviews: Path to a markdown file or document\n</requirements>\n\n## Main Tasks\n\n### 1. Determine Review Target & Setup (ALWAYS FIRST)\n\n<review_target> #$ARGUMENTS </review_target>\n\n<thinking>\nFirst, I need to determine the review target type and set up the code for analysis.\n</thinking>\n\n#### Immediate Actions:\n\n<task_list>\n\n- [ ] Determine review type: PR number (numeric), GitHub URL, file path (.md), or empty (current branch)\n- [ ] Check current git branch\n- [ ] If ALREADY on the target branch (PR branch, requested branch name, or the branch already checked out for review) ‚Üí proceed with analysis on current branch\n- [ ] If DIFFERENT branch than the review target ‚Üí offer to use worktree: \"Use git-worktree skill for isolated Call `skill: git-worktree` with branch name\n- [ ] Fetch PR metadata using `gh pr view --json` for title, body, files, linked issues\n- [ ] Set up language-specific analysis tools\n- [ ] Prepare security scanning environment\n- [ ] Make sure we are on the branch we are reviewing. Use gh pr checkout to switch to the branch or manually checkout the branch.\n\nEnsure that the code is ready for analysis (either in worktree or on current branch). ONLY then proceed to the next step.\n\n</task_list>\n\n#### Protected Artifacts\n\n<protected_artifacts>\nThe following paths are compound-engineering pipeline artifacts and must never be flagged for deletion, removal, or gitignore by any review agent:\n\n- `docs/plans/*.md` ‚Äî Plan files created by `/workflows:plan`. These are living documents that track implementation progress (checkboxes are checked off by `/workflows:work`).\n- `docs/solutions/*.md` ‚Äî Solution documents created during the pipeline.\n\nIf a review agent flags any file in these directories for cleanup or removal, discard that finding during synthesis. Do not create a todo for it.\n</protected_artifacts>\n\n#### Load Review Agents\n\nRead `compound-engineering.local.md` in the project root. If found, use `review_agents` from YAML frontmatter. If the markdown body contains review context, pass it to each agent as additional instructions.\n\nIf no settings file exists, invoke the `setup` skill to create one. Then read the newly created file and continue.\n\n#### Parallel Agents to review the PR:\n\n<parallel_tasks>\n\nRun all configured review agents in parallel using Task tool. For each agent in the `review_agents` list:\n\n```\nTask {agent-name}(PR content + review context from settings body)\n```\n\nAdditionally, always run these regardless of settings:\n- Task agent-native-reviewer(PR content) - Verify new features are agent-accessible\n- Task learnings-researcher(PR content) - Search docs/solutions/ for past issues related to this PR's modules and patterns\n\n</parallel_tasks>\n\n#### Conditional Agents (Run if applicable):\n\n<conditional_agents>\n\nThese agents are run ONLY when the PR matches specific criteria. Check the PR files list to determine if they apply:\n\n**MIGRATIONS: If PR contains database migrations, schema.rb, or data backfills:**\n\n- Task schema-drift-detector(PR content) - Detects unrelated schema.rb changes by cross-referencing against included migrations (run FIRST)\n- Task data-migration-expert(PR content) - Validates ID mappings match production, checks for swapped values, verifies rollback safety\n- Task deployment-verification-agent(PR content) - Creates Go/No-Go deployment checklist with SQL verification queries\n\n**When to run:**\n- PR includes files matching `db/migrate/*.rb` or `db/schema.rb`\n- PR modifies columns that store IDs, enums, or mappings\n- PR includes data backfill scripts or rake tasks\n- PR title/body mentions: migration, backfill, data transformation, ID mapping\n\n**What these agents check:**\n- `schema-drift-detector`: Cross-references schema.rb changes against PR migrations to catch unrelated columns/indexes from local database state\n- `data-migration-expert`: Verifies hard-coded mappings match production reality (prevents swapped IDs), checks for orphaned associations, validates dual-write patterns\n- `deployment-verification-agent`: Produces executable pre/post-deploy checklists with SQL queries, rollback procedures, and monitoring plans\n\n</conditional_agents>\n\n### 4. Ultra-Thinking Deep Dive Phases\n\n<ultrathink_instruction> For each phase below, spend maximum cognitive effort. Think step by step. Consider all angles. Question assumptions. And bring all reviews in a synthesis to the user.</ultrathink_instruction>\n\n<deliverable>\nComplete system context map with component interactions\n</deliverable>\n\n#### Phase 3: Stakeholder Perspective Analysis\n\n<thinking_prompt> ULTRA-THINK: Put yourself in each stakeholder's shoes. What matters to them? What are their pain points? </thinking_prompt>\n\n<stakeholder_perspectives>\n\n1. **Developer Perspective** <questions>\n\n   - How easy is this to understand and modify?\n   - Are the APIs intuitive?\n   - Is debugging straightforward?\n   - Can I test this easily? </questions>\n\n2. **Operations Perspective** <questions>\n\n   - How do I deploy this safely?\n   - What metrics and logs are available?\n   - How do I troubleshoot issues?\n   - What are the resource requirements? </questions>\n\n3. **End User Perspective** <questions>\n\n   - Is the feature intuitive?\n   - Are error messages helpful?\n   - Is performance acceptable?\n   - Does it solve my problem? </questions>\n\n4. **Security Team Perspective** <questions>\n\n   - What's the attack surface?\n   - Are there compliance requirements?\n   - How is data protected?\n   - What are the audit capabilities? </questions>\n\n5. **Business Perspective** <questions>\n   - What's the ROI?\n   - Are there legal/compliance risks?\n   - How does this affect time-to-market?\n   - What's the total cost of ownership? </questions> </stakeholder_perspectives>\n\n#### Phase 4: Scenario Exploration\n\n<thinking_prompt> ULTRA-THINK: Explore edge cases and failure scenarios. What could go wrong? How does the system behave under stress? </thinking_prompt>\n\n<scenario_checklist>\n\n- [ ] **Happy Path**: Normal operation with valid inputs\n- [ ] **Invalid Inputs**: Null, empty, malformed data\n- [ ] **Boundary Conditions**: Min/max values, empty collections\n- [ ] **Concurrent Access**: Race conditions, deadlocks\n- [ ] **Scale Testing**: 10x, 100x, 1000x normal load\n- [ ] **Network Issues**: Timeouts, partial failures\n- [ ] **Resource Exhaustion**: Memory, disk, connections\n- [ ] **Security Attacks**: Injection, overflow, DoS\n- [ ] **Data Corruption**: Partial writes, inconsistency\n- [ ] **Cascading Failures**: Downstream service issues </scenario_checklist>\n\n### 6. Multi-Angle Review Perspectives\n\n#### Technical Excellence Angle\n\n- Code craftsmanship evaluation\n- Engineering best practices\n- Technical documentation quality\n- Tooling and automation assessment\n\n#### Business Value Angle\n\n- Feature completeness validation\n- Performance impact on users\n- Cost-benefit analysis\n- Time-to-market considerations\n\n#### Risk Management Angle\n\n- Security risk assessment\n- Operational risk evaluation\n- Compliance risk verification\n- Technical debt accumulation\n\n#### Team Dynamics Angle\n\n- Code review etiquette\n- Knowledge sharing effectiveness\n- Collaboration patterns\n- Mentoring opportunities\n\n### 4. Simplification and Minimalism Review\n\nRun the Task code-simplicity-reviewer() to see if we can simplify the code.\n\n### 5. Findings Synthesis and Todo Creation Using file-todos Skill\n\n<critical_requirement> ALL findings MUST be stored in the todos/ directory using the file-todos skill. Create todo files immediately after synthesis - do NOT present findings for user approval first. Use the skill for structured todo management. </critical_requirement>\n\n#### Step 1: Synthesize All Findings\n\n<thinking>\nConsolidate all agent reports into a categorized list of findings.\nRemove duplicates, prioritize by severity and impact.\n</thinking>\n\n<synthesis_tasks>\n\n- [ ] Collect findings from all parallel agents\n- [ ] Surface learnings-researcher results: if past solutions are relevant, flag them as \"Known Pattern\" with links to docs/solutions/ files\n- [ ] Discard any findings that recommend deleting or gitignoring files in `docs/plans/` or `docs/solutions/` (see Protected Artifacts above)\n- [ ] Categorize by type: security, performance, architecture, quality, etc.\n- [ ] Assign severity levels: üî¥ CRITICAL (P1), üü° IMPORTANT (P2), üîµ NICE-TO-HAVE (P3)\n- [ ] Remove duplicate or overlapping findings\n- [ ] Estimate effort for each finding (Small/Medium/Large)\n\n</synthesis_tasks>\n\n#### Step 2: Create Todo Files Using file-todos Skill\n\n<critical_instruction> Use the file-todos skill to create todo files for ALL findings immediately. Do NOT present findings one-by-one asking for user approval. Create all todo files in parallel using the skill, then summarize results to user. </critical_instruction>\n\n**Implementation Options:**\n\n**Option A: Direct File Creation (Fast)**\n\n- Create todo files directly using Write tool\n- All findings in parallel for speed\n- Use standard template from `.opencode/skills/file-todos/assets/todo-template.md`\n- Follow naming convention: `{issue_id}-pending-{priority}-{description}.md`\n\n**Option B: Sub-Agents in Parallel (Recommended for Scale)** For large PRs with 15+ findings, use sub-agents to create finding files in parallel:\n\n```bash\n# Launch multiple finding-creator agents in parallel\nTask() - Create todos for first finding\nTask() - Create todos for second finding\nTask() - Create todos for third finding\netc. for each finding.\n```\n\nSub-agents can:\n\n- Process multiple findings simultaneously\n- Write detailed todo files with all sections filled\n- Organize findings by severity\n- Create comprehensive Proposed Solutions\n- Add acceptance criteria and work logs\n- Complete much faster than sequential processing\n\n**Execution Strategy:**\n\n1. Synthesize all findings into categories (P1/P2/P3)\n2. Group findings by severity\n3. Launch 3 parallel sub-agents (one per severity level)\n4. Each sub-agent creates its batch of todos using the file-todos skill\n5. Consolidate results and present summary\n\n**Process (Using file-todos Skill):**\n\n1. For each finding:\n\n   - Determine severity (P1/P2/P3)\n   - Write detailed Problem Statement and Findings\n   - Create 2-3 Proposed Solutions with pros/cons/effort/risk\n   - Estimate effort (Small/Medium/Large)\n   - Add acceptance criteria and work log\n\n2. Use file-todos skill for structured todo management:\n\n   ```bash\n   skill: file-todos\n   ```\n\n   The skill provides:\n\n   - Template location: `.opencode/skills/file-todos/assets/todo-template.md`\n   - Naming convention: `{issue_id}-{status}-{priority}-{description}.md`\n   - YAML frontmatter structure: status, priority, issue_id, tags, dependencies\n   - All required sections: Problem Statement, Findings, Solutions, etc.\n\n3. Create todo files in parallel:\n\n   ```bash\n   {next_id}-pending-{priority}-{description}.md\n   ```\n\n4. Examples:\n\n   ```\n   001-pending-p1-path-traversal-vulnerability.md\n   002-pending-p1-api-response-validation.md\n   003-pending-p2-concurrency-limit.md\n   004-pending-p3-unused-parameter.md\n   ```\n\n5. Follow template structure from file-todos skill: `.opencode/skills/file-todos/assets/todo-template.md`\n\n**Todo File Structure (from template):**\n\nEach todo must include:\n\n- **YAML frontmatter**: status, priority, issue_id, tags, dependencies\n- **Problem Statement**: What's broken/missing, why it matters\n- **Findings**: Discoveries from agents with evidence/location\n- **Proposed Solutions**: 2-3 options, each with pros/cons/effort/risk\n- **Recommended Action**: (Filled during triage, leave blank initially)\n- **Technical Details**: Affected files, components, database changes\n- **Acceptance Criteria**: Testable checklist items\n- **Work Log**: Dated record with actions and learnings\n- **Resources**: Links to PR, issues, documentation, similar patterns\n\n**File naming convention:**\n\n```\n{issue_id}-{status}-{priority}-{description}.md\n\nExamples:\n- 001-pending-p1-security-vulnerability.md\n- 002-pending-p2-performance-optimization.md\n- 003-pending-p3-code-cleanup.md\n```\n\n**Status values:**\n\n- `pending` - New findings, needs triage/decision\n- `ready` - Approved by manager, ready to work\n- `complete` - Work finished\n\n**Priority values:**\n\n- `p1` - Critical (blocks merge, security/data issues)\n- `p2` - Important (should fix, architectural/performance)\n- `p3` - Nice-to-have (enhancements, cleanup)\n\n**Tagging:** Always add `code-review` tag, plus: `security`, `performance`, `architecture`, `rails`, `quality`, etc.\n\n#### Step 3: Summary Report\n\nAfter creating all todo files, present comprehensive summary:\n\n````markdown\n## ‚úÖ Code Review Complete\n\n**Review Target:** PR #XXXX - [PR Title] **Branch:** [branch-name]\n\n### Findings Summary:\n\n- **Total Findings:** [X]\n- **üî¥ CRITICAL (P1):** [count] - BLOCKS MERGE\n- **üü° IMPORTANT (P2):** [count] - Should Fix\n- **üîµ NICE-TO-HAVE (P3):** [count] - Enhancements\n\n### Created Todo Files:\n\n**P1 - Critical (BLOCKS MERGE):**\n\n- `001-pending-p1-{finding}.md` - {description}\n- `002-pending-p1-{finding}.md` - {description}\n\n**P2 - Important:**\n\n- `003-pending-p2-{finding}.md` - {description}\n- `004-pending-p2-{finding}.md` - {description}\n\n**P3 - Nice-to-Have:**\n\n- `005-pending-p3-{finding}.md` - {description}\n\n### Review Agents Used:\n\n- kieran-rails-reviewer\n- security-sentinel\n- performance-oracle\n- architecture-strategist\n- agent-native-reviewer\n- [other agents]\n\n### Next Steps:\n\n1. **Address P1 Findings**: CRITICAL - must be fixed before merge\n\n   - Review each P1 todo in detail\n   - Implement fixes or request exemption\n   - Verify fixes before merging PR\n\n2. **Triage All Todos**:\n   ```bash\n   ls todos/*-pending-*.md  # View all pending todos\n   /triage                  # Use slash command for interactive triage\n   ```\n````\n\n3. **Work on Approved Todos**:\n\n   ```bash\n   /resolve_todo_parallel  # Fix all approved items efficiently\n   ```\n\n4. **Track Progress**:\n   - Rename file when status changes: pending ‚Üí ready ‚Üí complete\n   - Update Work Log as you work\n   - Commit todos: `git add todos/ && git commit -m \"refactor: add code review findings\"`\n\n### Severity Breakdown:\n\n**üî¥ P1 (Critical - Blocks Merge):**\n\n- Security vulnerabilities\n- Data corruption risks\n- Breaking changes\n- Critical architectural issues\n\n**üü° P2 (Important - Should Fix):**\n\n- Performance issues\n- Significant architectural concerns\n- Major code quality problems\n- Reliability issues\n\n**üîµ P3 (Nice-to-Have):**\n\n- Minor improvements\n- Code cleanup\n- Optimization opportunities\n- Documentation updates\n\n```\n\n### 7. End-to-End Testing (Optional)\n\n<detect_project_type>\n\n**First, detect the project type from PR files:**\n\n| Indicator | Project Type |\n|-----------|--------------|\n| `*.xcodeproj`, `*.xcworkspace`, `Package.swift` (iOS) | iOS/macOS |\n| `Gemfile`, `package.json`, `app/views/*`, `*.html.*` | Web |\n| Both iOS files AND web files | Hybrid (test both) |\n\n</detect_project_type>\n\n<offer_testing>\n\nAfter presenting the Summary Report, offer appropriate testing based on project type:\n\n**For Web Projects:**\n```markdown\n**\"Want to run browser tests on the affected pages?\"**\n1. Yes - run `/test-browser`\n2. No - skip\n```\n\n**For iOS Projects:**\n```markdown\n**\"Want to run Xcode simulator tests on the app?\"**\n1. Yes - run `/xcode-test`\n2. No - skip\n```\n\n**For Hybrid Projects (e.g., Rails + Hotwire Native):**\n```markdown\n**\"Want to run end-to-end tests?\"**\n1. Web only - run `/test-browser`\n2. iOS only - run `/xcode-test`\n3. Both - run both commands\n4. No - skip\n```\n\n</offer_testing>\n\n#### If User Accepts Web Testing:\n\nSpawn a subagent to run browser tests (preserves main context):\n\n```\nTask general-purpose(\"Run /test-browser for PR #[number]. Test all affected pages, check for console errors, handle failures by creating todos and fixing.\")\n```\n\nThe subagent will:\n1. Identify pages affected by the PR\n2. Navigate to each page and capture snapshots (using Playwright MCP or agent-browser CLI)\n3. Check for console errors\n4. Test critical interactions\n5. Pause for human verification on OAuth/email/payment flows\n6. Create P1 todos for any failures\n7. Fix and retry until all tests pass\n\n**Standalone:** `/test-browser [PR number]`\n\n#### If User Accepts iOS Testing:\n\nSpawn a subagent to run Xcode tests (preserves main context):\n\n```\nTask general-purpose(\"Run /xcode-test for scheme [name]. Build for simulator, install, launch, take screenshots, check for crashes.\")\n```\n\nThe subagent will:\n1. Verify XcodeBuildMCP is installed\n2. Discover project and schemes\n3. Build for iOS Simulator\n4. Install and launch app\n5. Take screenshots of key screens\n6. Capture console logs for errors\n7. Pause for human verification (Sign in with Apple, push, IAP)\n8. Create P1 todos for any failures\n9. Fix and retry until all tests pass\n\n**Standalone:** `/xcode-test [scheme]`\n\n### Important: P1 Findings Block Merge\n\nAny **üî¥ P1 (CRITICAL)** findings must be addressed before merging the PR. Present these prominently and ensure they're resolved before accepting the PR.\n```"
    },
    "workflows:brainstorm": {
      "description": "Explore requirements and approaches through collaborative dialogue before planning implementation",
      "template": "# Brainstorm a Feature or Improvement\n\n**Note: The current year is 2026.** Use this when dating brainstorm documents.\n\nBrainstorming helps answer **WHAT** to build through collaborative dialogue. It precedes `/workflows:plan`, which answers **HOW** to build it.\n\n**Process knowledge:** Load the `brainstorming` skill for detailed question techniques, approach exploration patterns, and YAGNI principles.\n\n## Feature Description\n\n<feature_description> #$ARGUMENTS </feature_description>\n\n**If the feature description above is empty, ask the user:** \"What would you like to explore? Please describe the feature, problem, or improvement you're thinking about.\"\n\nDo not proceed until you have a feature description from the user.\n\n## Execution Flow\n\n### Phase 0: Assess Requirements Clarity\n\nEvaluate whether brainstorming is needed based on the feature description.\n\n**Clear requirements indicators:**\n- Specific acceptance criteria provided\n- Referenced existing patterns to follow\n- Described exact expected behavior\n- Constrained, well-defined scope\n\n**If requirements are already clear:**\nUse **AskUserQuestion tool** to suggest: \"Your requirements seem detailed enough to proceed directly to planning. Should I run `/workflows:plan` instead, or would you like to explore the idea further?\"\n\n### Phase 1: Understand the Idea\n\n#### 1.1 Repository Research (Lightweight)\n\nRun a quick repo scan to understand existing patterns:\n\n- Task repo-research-analyst(\"Understand existing patterns related to: <feature_description>\")\n\nFocus on: similar features, established patterns, CLAUDE.md guidance.\n\n#### 1.2 Collaborative Dialogue\n\nUse the **AskUserQuestion tool** to ask questions **one at a time**.\n\n**Guidelines (see `brainstorming` skill for detailed techniques):**\n- Prefer multiple choice when natural options exist\n- Start broad (purpose, users) then narrow (constraints, edge cases)\n- Validate assumptions explicitly\n- Ask about success criteria\n\n**Exit condition:** Continue until the idea is clear OR user says \"proceed\"\n\n### Phase 2: Explore Approaches\n\nPropose **2-3 concrete approaches** based on research and conversation.\n\nFor each approach, provide:\n- Brief description (2-3 sentences)\n- Pros and cons\n- When it's best suited\n\nLead with your recommendation and explain why. Apply YAGNI‚Äîprefer simpler solutions.\n\nUse **AskUserQuestion tool** to ask which approach the user prefers.\n\n### Phase 3: Capture the Design\n\nWrite a brainstorm document to `docs/brainstorms/YYYY-MM-DD-<topic>-brainstorm.md`.\n\n**Document structure:** See the `brainstorming` skill for the template format. Key sections: What We're Building, Why This Approach, Key Decisions, Open Questions.\n\nEnsure `docs/brainstorms/` directory exists before writing.\n\n**IMPORTANT:** Before proceeding to Phase 4, check if there are any Open Questions listed in the brainstorm document. If there are open questions, YOU MUST ask the user about each one using AskUserQuestion before offering to proceed to planning. Move resolved questions to a \"Resolved Questions\" section.\n\n### Phase 4: Handoff\n\nUse **AskUserQuestion tool** to present next steps:\n\n**Question:** \"Brainstorm captured. What would you like to do next?\"\n\n**Options:**\n1. **Review and refine** - Improve the document through structured self-review\n2. **Proceed to planning** - Run `/workflows:plan` (will auto-detect this brainstorm)\n3. **Ask more questions** - I have more questions to clarify before moving on\n4. **Done for now** - Return later\n\n**If user selects \"Ask more questions\":** YOU (Claude) return to Phase 1.2 (Collaborative Dialogue) and continue asking the USER questions one at a time to further refine the design. The user wants YOU to probe deeper - ask about edge cases, constraints, preferences, or areas not yet explored. Continue until the user is satisfied, then return to Phase 4.\n\n**If user selects \"Review and refine\":**\n\nLoad the `document-review` skill and apply it to the brainstorm document.\n\nWhen document-review returns \"Review complete\", present next steps:\n\n1. **Move to planning** - Continue to `/workflows:plan` with this document\n2. **Done for now** - Brainstorming complete. To start planning later: `/workflows:plan [document-path]`\n\n## Output Summary\n\nWhen complete, display:\n\n```\nBrainstorm complete!\n\nDocument: docs/brainstorms/YYYY-MM-DD-<topic>-brainstorm.md\n\nKey decisions:\n- [Decision 1]\n- [Decision 2]\n\nNext: Run `/workflows:plan` when ready to implement.\n```\n\n## Important Guidelines\n\n- **Stay focused on WHAT, not HOW** - Implementation details belong in the plan\n- **Ask one question at a time** - Don't overwhelm\n- **Apply YAGNI** - Prefer simpler approaches\n- **Keep outputs concise** - 200-300 words per section max\n\nNEVER CODE! Just explore and document decisions."
    },
    "resolve_todo_parallel": {
      "description": "Resolve all pending CLI todos using parallel processing",
      "template": "Resolve all TODO comments using parallel processing.\n\n## Workflow\n\n### 1. Analyze\n\nGet all unresolved TODOs from the /todos/\\*.md directory\n\nIf any todo recommends deleting, removing, or gitignoring files in `docs/plans/` or `docs/solutions/`, skip it and mark it as `wont_fix`. These are compound-engineering pipeline artifacts that are intentional and permanent.\n\n### 2. Plan\n\nCreate a TodoWrite list of all unresolved items grouped by type.Make sure to look at dependencies that might occur and prioritize the ones needed by others. For example, if you need to change a name, you must wait to do the others. Output a mermaid flow diagram showing how we can do this. Can we do everything in parallel? Do we need to do one first that leads to others in parallel? I'll put the to-dos in the mermaid diagram flow‚Äëwise so the agent knows how to proceed in order.\n\n### 3. Implement (PARALLEL)\n\nSpawn a pr-comment-resolver agent for each unresolved item in parallel.\n\nSo if there are 3 comments, it will spawn 3 pr-comment-resolver agents in parallel. liek this\n\n1. Task pr-comment-resolver(comment1)\n2. Task pr-comment-resolver(comment2)\n3. Task pr-comment-resolver(comment3)\n\nAlways run all in parallel subagents/Tasks for each Todo item.\n\n### 4. Commit & Resolve\n\n- Commit changes\n- Remove the TODO from the file, and mark it as resolved.\n- Push to remote"
    }
  },
  "mcp": {
    "context7": {
      "type": "remote",
      "url": "https://mcp.context7.com/mcp",
      "enabled": true
    },
    "kapture": {
      "type": "local",
      "command": ["npx", "-y", "kapture-mcp", "bridge"]
    }
  },
  "permission": {
    "read": "allow",
    "write": "allow",
    "edit": "allow",
    "bash": "allow",
    "grep": "allow",
    "glob": "allow",
    "list": "allow",
    "webfetch": "allow",
    "skill": "allow",
    "patch": "allow",
    "task": "allow",
    "question": "allow",
    "todowrite": "allow",
    "todoread": "allow"
  },
  "tools": {
    "read": true,
    "write": true,
    "edit": true,
    "bash": true,
    "grep": true,
    "glob": true,
    "list": true,
    "webfetch": true,
    "skill": true,
    "patch": true,
    "task": true,
    "question": true,
    "todowrite": true,
    "todoread": true
  }
}
